{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f03f6b97-8960-4ef8-9f8b-4ba430c5640c",
   "metadata": {},
   "source": [
    "# Introducing Mistral Large 2 (24.07)\n",
    "\n",
    "[Mistral Large 2](https://mistral.ai/news/mistral-large-2407/) is an advanced large language model with state-of-the-art reasoning, knowledge, and coding capabilities according to Mistral. Mistral Large 2 is designed for single-node inference with long-context applications in mind – its size of 123 billion parameters allows it to run at large throughput on a single node. A significant effort was also devoted by Mistral to enhancing the model's reasoning capabilities. One of Mistral's key focuses during training was to minimize the model's tendency to \"hallucinate,\" or generate plausible-sounding but factually incorrect or irrelevant information. This was achieved by fine-tuning the model to be more cautious and discerning in its responses, ensuring that it provides reliable and accurate outputs. Additionally, the new Mistral Large is trained to acknowledge when it cannot find solutions or does not have sufficient information to provide a confident answer. Mistral Large 2 sets a new frontier in terms of performance / cost of serving on evaluation metrics. In particular, on MMLU, the pretrained version achieves an accuracy of 84.0%, and sets a new point on the performance/cost Pareto front of open models.\n",
    "\n",
    "The model is currently generally available for use on [Amazon Bedrock](https://aws.amazon.com/bedrock/), check out the [blog] post for more info.\n",
    "\n",
    "In this notebook we will be demonstrating a number of different features like multilingual capabilities (optimized for character-based languages), function calling and tool use, json output, math and reasoning, and code generation with Bedrock's [Converse API](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_Converse.html).\n",
    "\n",
    "--- \n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>IMPORTANT:</b>  Mistral Large 2 is being released under the <a href=\"https://mistral.ai/licenses/MRL-0.1.md\"> Mistral Research License</a>, that allows usage and modification for research and non-commercial usages. \n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "### Multi-lingual by design\n",
    "\n",
    "Dozens of languages supported, including English, French, German, Spanish, Italian, Chinese, Japanese, Korean, Arabic, Portuguese, Dutch and Polish among others. In particular, it excels in English, French, German, Spanish, Italian, Portuguese, Dutch, Russian, Chinese, Japanese, Korean, Arabic, and Hindi. Below are the performance results of Mistral Large 2 on the multilingual MMLU benchmark, compared to the previous Mistral Large, Llama 3.1 models, and to Cohere’s Command R+.\n",
    "\n",
    "#### Performance on Multilingual MMLU (measured on the base pretrained model)\n",
    "\n",
    "![multilingual-mmlu](imgs/mistral-large-2407-language-diversity.webp)\n",
    "\n",
    "\n",
    "---\n",
    "### Proficient in Code and Reasoning\n",
    "\n",
    "Trained on 80+ coding languages such as Python, Java, C, C++, JavaScript, Bash, Swift, Fortran. Following their experience with Codestral 22B and Codestral Mamba, Mistral has trained Mistral Large 2 on a very large proportion of code. It vastly outperforms the previous Mistral Large, and performs on par with leading models such as GPT-4o, Claude 3 Opus, and Llama 3 405B.\n",
    "\n",
    "#### Performance accuracy on code generation benchmarks (all models were benchmarked through the same evaluation pipeline)\n",
    "\n",
    "![code-gen](imgs/mistral-large-2407-code-generation.png)\n",
    "\n",
    "\n",
    "#### Performance accuracy on MultiPL-E (all models were benchmarked through the same evaluation pipeline, except for the \"paper\" row)\n",
    "\n",
    "![code-multiple](imgs/mistral-large-2407-multiple.webp)\n",
    "\n",
    "---\n",
    "### Agent-centric\n",
    "\n",
    "Best-in-class agentic capabilities with native function calling and JSON outputting. Mistral Large 2 is equipped with enhanced function calling and retrieval skills and has undergone training to proficiently execute both parallel and sequential function calls, enabling it to serve as the power engine of complex business applications.\n",
    "\n",
    "![tool-use](imgs/mistral-large-2407-tool-use.png)\n",
    "\n",
    "---\n",
    "## Model Card\n",
    "\n",
    "<b>Available regions: US-West-2</b>\n",
    "\n",
    "<b>Model ID: mistral.mistral-large-2407-v1:0</b>\n",
    "\n",
    "<b>Context Window : 128k</b>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e889b428-f220-4aa1-866d-43910e930bb2",
   "metadata": {},
   "source": [
    "Lets get started with trying out the model on Bedrock!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9366393c-b0c6-4ee9-9ef1-9d74da0a8b6c",
   "metadata": {},
   "source": [
    "#### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ee83c4b-a59b-4ae7-a443-d23b665e660e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from boto3 import client\n",
    "from botocore.config import Config\n",
    "import json\n",
    "import logging\n",
    "from botocore.exceptions import ClientError\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd992f67-4ffc-4b01-b235-de2fcd2ee5b3",
   "metadata": {},
   "source": [
    "#### Create Bedrock Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bed39c4f-f50c-47fc-bd6a-4597594b5e37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    }
   ],
   "source": [
    "config = Config(read_timeout=2000)\n",
    "bedrock_client = boto3.client(service_name='bedrock-runtime', region_name=\"us-west-2\", config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ef8c55-7eab-4f86-ab3a-c60cb5db34c9",
   "metadata": {},
   "source": [
    "#### Instantiate model ids of mistral models being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b987d7bb-a773-4ede-9fba-4b4b4ea230a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mistral_large_v1 = 'mistral.mistral-large-2402-v1:0'\n",
    "mistral_large_2 = 'mistral.mistral-large-2407-v1:0'\n",
    "\n",
    "model_id = mistral_large_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45307e95-7e1d-41cd-a13a-a4d81d2b5f17",
   "metadata": {},
   "source": [
    "### Generating JSON  & Tool Use\n",
    "\n",
    "Mistral 2 now offers a native JSON output mode. This feature allows developers to receive the model's responses in a structured, easy-to-read format that can be readily integrated into various applications and systems. With JSON being a widely adopted data exchange standard, this capability simplifies the process of working with the model's outputs, making it more accessible and practical for developers across different domains and use cases.\n",
    "\n",
    "To generate JSON with the Converse API you will need to define a toolSpec. Here we’ve outlined an example for a travel agent company that will take passenger information and requests and convert them to JSON.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a30cdcb2-7f7e-49d6-9db8-c2061534c6bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the tool configuration\n",
    "import json\n",
    "tool_list = [\n",
    "    {\n",
    "        \"toolSpec\": {\n",
    "            \"name\": \"travel_agent\",\n",
    "            \"description\": \"Converts trip details as a json structure.\",\n",
    "            \"inputSchema\": {\n",
    "                \"json\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"origin_airport\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Origin airport (IATA code)\"\n",
    "                        },\n",
    "                        \"destination_airport\": {\n",
    "                            \"type\": \"boolean\",\n",
    "                            \"description\": \"Destination airport (IATA code)\"\n",
    "                        },\n",
    "                        \"departure_date\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Departure date\",\n",
    "                        }, \n",
    "                        \"return_date\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Return date\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\n",
    "                        \"origin_airport\",\n",
    "                        \"destination_airport\",\n",
    "                        \"departure_date\",\n",
    "                        \"return_date\"\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1439f636-4660-48a4-9fda-7fc54427bd44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "content = \"\"\"\n",
    "I would like to book a flight from New York (JFK) to London (LHR) for a round-trip.\n",
    "The departure date is June 15, 2023, and the return date is June 25, 2023.\n",
    "\n",
    "For the flight preferences, I would prefer to fly with Delta or United Airlines. \n",
    "My preferred departure time range is between 8 AM and 11 AM, and my preferred arrival time range is between 9 AM and 1 PM (local time in London). \n",
    "I am open to flights with one stop, but no more than that.\n",
    "Please include non-stop flight options if available.\n",
    "\"\"\"\n",
    "\n",
    "message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        { \"text\": f\"<content>{content}</content>\" },\n",
    "        { \"text\": \"Please create a well-structured JSON object representing the flight booking request, ensuring proper nesting and organization of the data. Include sample data for better understanding. Create the JSON based on the content within the <content> tags.\" }\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9835ccf3-1217-4cef-a477-82c288906085",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m response_content_blocks \u001b[38;5;241m=\u001b[39m response_message[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     16\u001b[0m content_block \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m((block \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m response_content_blocks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoolUse\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m block), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 17\u001b[0m tool_use_block \u001b[38;5;241m=\u001b[39m \u001b[43mcontent_block\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtoolUse\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     18\u001b[0m tool_result_dict \u001b[38;5;241m=\u001b[39m tool_use_block[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(tool_result_dict, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Bedrock client configuration\n",
    "response = bedrock_client.converse(\n",
    "    modelId=model_id,\n",
    "    messages=[message],\n",
    "    inferenceConfig={\n",
    "        \"maxTokens\": 500,\n",
    "        \"temperature\": 0.1\n",
    "    },\n",
    "    toolConfig={\n",
    "        \"tools\": tool_list\n",
    "    }\n",
    ")\n",
    "\n",
    "response_message = response['output']['message']\n",
    "response_content_blocks = response_message['content']\n",
    "content_block = next((block for block in response_content_blocks if 'toolUse' in block), None)\n",
    "tool_use_block = content_block['toolUse']\n",
    "tool_result_dict = tool_use_block['input']\n",
    "\n",
    "print(json.dumps(tool_result_dict, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f339d21e-7e0d-402f-b425-0ad849f3463b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '7cdbaec1-f8ef-47fd-b12e-7f244cbba70e', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Wed, 24 Jul 2024 15:56:57 GMT', 'content-type': 'application/json', 'content-length': '1160', 'connection': 'keep-alive', 'x-amzn-requestid': '7cdbaec1-f8ef-47fd-b12e-7f244cbba70e'}, 'RetryAttempts': 0}, 'output': {'message': {'role': 'assistant', 'content': [{'text': 'Sure, here\\'s a JSON representation of your flight booking request:\\n\\n```json\\n{\\n  \"flight_booking_request\": {\\n    \"trip_type\": \"round_trip\",\\n    \"origin_airport\": \"JFK\",\\n    \"destination_airport\": \"LHR\",\\n    \"departure_date\": \"2023-06-15\",\\n    \"return_date\": \"2023-06-25\",\\n    \"flight_preferences\": {\\n      \"preferred_airlines\": [\"Delta\", \"United Airlines\"],\\n      \"departure_time_preference\": {\\n        \"from\": \"08:00\",\\n        \"to\": \"11:00\"\\n      },\\n      \"arrival_time_preference\": {\\n        \"from\": \"09:00\",\\n        \"to\": \"13:00\"\\n      },\\n      \"max_stops\": 1,\\n      \"include_non_stop_flights\": true\\n    }\\n  }\\n}\\n```\\n\\nThis JSON object includes all the details you provided, such as the trip type, airports, dates, preferred airlines, and time preferences. It also includes your preference for flights with no more than one stop and your request to include non-stop flight options if available.'}]}}, 'stopReason': 'end_turn', 'usage': {'inputTokens': 367, 'outputTokens': 312, 'totalTokens': 679}, 'metrics': {'latencyMs': 8192}}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5284f190-03d8-482f-96a5-570c1cb60526",
   "metadata": {
    "tags": []
   },
   "source": [
    "Mistral Large 2 was able to correctly take our user query and convert the appropriate information to JSON. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9347970c-0c17-43c3-9a34-bd623e6729af",
   "metadata": {},
   "source": [
    "\n",
    "### Converse API & Tool Use\n",
    "\n",
    "Mistral Large 2 also supports the Converse API & tool use. You can use the Amazon Bedrock API to give a model access to tools that can help it generate responses for messages that you send to the model. For example, you might have a chat application that lets users find out out the most popular song played on a radio station. To answer a request for the most popular song, a model needs a tool that can query and return the song information. Here we have an example for getting the correct train schedule.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b857ec47-db95-4bd0-a63a-36127e9d02a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tool configuration\n",
    "toolConfig = {\n",
    "    \"tools\": [\n",
    "        {\n",
    "            \"toolSpec\": {\n",
    "                \"name\": \"shinkansen_schedule\",\n",
    "                \"description\": \"Fetches Shinkansen train schedule departure times for a specified station and time.\",\n",
    "                \"inputSchema\": {\n",
    "                    \"json\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"station\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The station name.\"\n",
    "                            },\n",
    "                            \"departure_time\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The departure time in HH:MM format.\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"station\", \"departure_time\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "457fda19-94d0-4d63-bba0-8a3639bce2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tool configuration\n",
    "toolConfig = {\n",
    "    \"tools\": [\n",
    "        {\n",
    "            \"toolSpec\": {\n",
    "                \"name\": \"shinkansen_schedule\",\n",
    "                \"description\": \"Fetches Shinkansen train schedule departure times for a specified station and time.\",\n",
    "                \"inputSchema\": {\n",
    "                    \"json\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"station\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The station name.\"\n",
    "                            },\n",
    "                            \"departure_time\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The departure time in HH:MM format.\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"station\", \"departure_time\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a70fa882-542c-406d-810e-72607867d966",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def shinkansen_schedule(station, departure_time):\n",
    "    schedule = {\n",
    "        \"Tokyo\": {\"09:00\": \"Hikari\", \"12:00\": \"Nozomi\", \"15:00\": \"Kodama\"},\n",
    "        \"Osaka\": {\"10:00\": \"Nozomi\", \"13:00\": \"Hikari\", \"16:00\": \"Kodama\"}\n",
    "    }\n",
    "    return schedule.get(station, {}).get(departure_time, \"No train found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dd2372f-3330-4a39-884c-bf60f8b391b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_mistral(prompt):\n",
    "    messages = [{\"role\": \"user\", \"content\": [{\"text\": prompt}]}]\n",
    "    converse_api_params = {\n",
    "        \"modelId\": model_id,\n",
    "        \"messages\": messages,\n",
    "        \"toolConfig\": toolConfig,  \n",
    "        \"inferenceConfig\": {\"temperature\": 0.0, \"maxTokens\": 400},\n",
    "    }\n",
    "\n",
    "    response = bedrock_client.converse(**converse_api_params)\n",
    "    \n",
    "    if response['output']['message']['content'][0].get('toolUse'):\n",
    "        tool_use = response['output']['message']['content'][0]['toolUse']\n",
    "        tool_name = tool_use['name']\n",
    "        tool_inputs = tool_use['input']\n",
    "\n",
    "        if tool_name == \"shinkansen_schedule\":\n",
    "            print(\"Mistral wants to use the shinkansen_schedule tool\")\n",
    "            station = tool_inputs[\"station\"]\n",
    "            departure_time = tool_inputs[\"departure_time\"]\n",
    "            \n",
    "            try:\n",
    "                result = shinkansen_schedule(station, departure_time)\n",
    "                print(\"Train schedule result:\", result)\n",
    "            except ValueError as e:\n",
    "                print(f\"Error: {str(e)}\")\n",
    "\n",
    "    else:\n",
    "        print(\"Mistral responded with:\")\n",
    "        print(response['output']['message']['content'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05e2c11b-b406-4889-9edb-6194a2b1bbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mistral wants to use the shinkansen_schedule tool\n",
      "Train schedule result: Hikari\n"
     ]
    }
   ],
   "source": [
    "prompt_mistral(\"What train departs Tokyo at 9:00?\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a4a156-9d5c-4988-bec2-27df931cb665",
   "metadata": {
    "tags": []
   },
   "source": [
    "Mistral Large 2 was able to correctly identify the shinkansen tool and demonstrate its use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8109a915-b96c-4db7-a865-e164a7df798a",
   "metadata": {},
   "source": [
    "### Multilingual \n",
    "\n",
    "Mistral Large 2 now supports a large number of character-based languages such as Chinese, Japanese, Korean, Arabic, and Hindi. This expanded language support allows developers to build applications and services that can cater to users from diverse linguistic backgrounds. With multilingual capabilities, developers can create localized user interfaces, provide language-specific content and resources, and ensure a seamless experience for users regardless of their native language. In particular, Mistral Large's efficiency with character-based languages can be tested by comparing how it performs in comparison to Mistral Large v1.\n",
    "\n",
    "Here, let's try to translate customer emails generated by the author into different languages such as Hindi & Japanese. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e689aa40-d56d-4495-896a-ee8d58192124",
   "metadata": {},
   "source": [
    "#### Mistral Large v1\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4727948-b8a4-4028-abe6-e14035469349",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails= \"\"\"\n",
    "\"I recently bought your RGB gaming keyboard and absolutely love the customizable lighting features! Can you guide me on how to set up different profiles for each game I play?\"\n",
    "\"I'm trying to use the macro keys on the gaming keyboard I just purchased, but they don't seem to be registering my inputs. Could you help me figure out what might be going wrong?\"\n",
    "\"I'm considering buying your gaming keyboard and I'm curious about the key switch types. What options are available and what are their main differences?\"\n",
    "\"I wanted to report a small issue where my keyboard's space bar is a bit squeaky. However, your quick-start guide was super helpful and I fixed it easily by following the lubrication tips. Just thought you might want to know!\"\n",
    "\"My new gaming keyboard stopped working within a week of purchase. None of the keys respond, and the lights don't turn on. I need a solution or a replacement as soon as possible.\"\n",
    "\"I've noticed that the letters on the keys of my gaming keyboard are starting to fade after several months of use. Is this covered by the warranty?\"\n",
    "\"I had an issue where my keyboard settings would reset every time I restarted my PC. I figured out it was due to a software conflict and resolved it by updating the firmware. Just wanted to ask if there are any new updates coming soon?\"\n",
    "\"I've been having trouble with the keyboard software not saving my configurations, and it's starting to get frustrating. What can be done to ensure my settings are saved permanently?\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1dc0ffa7-0735-4de5-8a0d-e277b49c1ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. \"私は最近、RGBゲーミングキーボードを購入し、カスタマイズ可能なライティング機能がとても好きです！私がプレイする各ゲームに対して異なるプロファイルを設定する方法をガイドくださいませんか？\"\n",
      "2. \"私は今までに購入したゲーミングキーボードのマクロキーを使おうとしていますが、入力が認識されません。何か問題があるかどうかを特定してくださいませんか？\"\n",
      "3. \"ゲームキーボードを購入考えていますが、キースイッチのタイプについて気になっています。どのようなオプションがあり、それらの主な違いは何ですか？\"\n",
      "4. \"私は、スペースバーが少しきしんと音がしますという小さな問題を報告したいと思います。しかし、迅速なスタートガイドはとても役立ち、潤滑油の使用方法に従って簡単に修理できました。知らせておくだけです！\"\n",
      "5. \"私の新しいゲーミングキーボードは購入後すぐに動作を停止しました。キーが反応しないし、ライトがつきません。できるだけ早く解決策または交換品をお願いします。\"\n",
      "6. \"ゲーミングキーボードのキーの文字が数か月経ってから消え始めたことに気づきました。保証にカバーされていますか？\"\n",
      "7. \"キーボードの設定がPCを再起動するたびにリセットされる問題がありました。ソフトウェアの競合が原因であることがわかり、ファームウェアを更新することで解決しました。新しい更新プログラムが近日中に来るかどうか単に尋ねたいと思います？\"\n",
      "8. \"キーボードソフトウェアが設定を永久的に保存しない問題があります。設定が永久的に保存されるようにするために何ができるか教えてくださいませんか？\"\n"
     ]
    }
   ],
   "source": [
    "def converse(prompt, inference_config):\n",
    "    messages = [{\"role\": \"user\", \"content\": [{\"text\": prompt}]}]\n",
    "    response = bedrock_client.converse(\n",
    "        messages=messages,\n",
    "        modelId=mistral_large_v1,\n",
    "        inferenceConfig=inference_config\n",
    "    )\n",
    "    generated_text = response['output']['message']['content'][0]['text']\n",
    "    print(generated_text)\n",
    "    return generated_text, response\n",
    "\n",
    "prompt=f\"\"\"\n",
    "\n",
    "emails={emails}\n",
    "\n",
    "Translate the following customer emails into Japanese. Your response must only translate the emails.\n",
    "\n",
    "\n",
    "\"\"\".format(emails=emails)\n",
    "\n",
    "inference_config = {\"temperature\": 0.0, \"maxTokens\": 4000, \"topP\": 0.1}\n",
    "\n",
    "generated_text, response = converse(prompt, inference_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0aebe151-7991-4f1c-9b91-fff5032fca8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: {\n",
      "    \"inputTokens\": 362,\n",
      "    \"outputTokens\": 725,\n",
      "    \"totalTokens\": 1087\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Usage:\", json.dumps(response['usage'], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfee2cf-0312-41b2-8251-dd5162cc8e65",
   "metadata": {},
   "source": [
    "#### Mistral Large 2\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7273020-d76b-4e67-b1f3-11f09add565e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def converse(prompt, inference_config):\n",
    "    messages = [{\"role\": \"user\", \"content\": [{\"text\": prompt}]}]\n",
    "    response = bedrock_client.converse(\n",
    "        messages=messages,\n",
    "        modelId=model_id,\n",
    "        inferenceConfig=inference_config\n",
    "    )\n",
    "    generated_text = response['output']['message']['content'][0]['text']\n",
    "    print(generated_text)\n",
    "    return generated_text, response\n",
    "\n",
    "prompt=f\"\"\"\n",
    "\n",
    "emails={emails}\n",
    "\n",
    "Translate the following customer emails into Japanese. Your response must only translate the emails.\n",
    "\n",
    "\n",
    "\"\"\".format(emails=emails)\n",
    "\n",
    "inference_config = {\"temperature\": 0.0, \"maxTokens\": 4000, \"topP\": 0.1}\n",
    "\n",
    "generated_text, response = converse(prompt, inference_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7bd258-0d12-4e15-9a1b-480190132c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b910897a-9431-46f9-ae80-2601fc7d7325",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b57678-4123-4239-a1a5-89bf04f3c2e0",
   "metadata": {},
   "source": [
    "### Coding Tasks\n",
    "\n",
    "Mistral Large 2 has been trained on over 80 coding languages, including popular ones like Python, Java, C, C++, JavaScript, and Bash, as well as more specialized languages such as Swift and Fortran. This comprehensive language support empowers developers to tackle a wide range of coding tasks and projects across various domains and platforms. Whether you're working on web development, mobile applications, scientific computing, or system programming, Mistral 2 can assist you with code generation, debugging, refactoring, and other coding-related tasks.\n",
    "\n",
    "Sample coding tasks:\n",
    "\n",
    "1. \"Create a Python class for a multi-threaded web scraper that can handle rate limiting, proxy rotation, and dynamic content loading. Include methods for parsing HTML with BeautifulSoup and storing results in a SQLite database.\"\n",
    "2. \"Implement a Red-Black Tree data structure in C++ with methods for insertion, deletion, and rebalancing. Include a visualization function that prints the tree structure to the console.\"\n",
    "3. \"Write a Rust function that implements the Aho-Corasick string matching algorithm for efficient multi-pattern searching. Optimize it for memory usage and include comprehensive error handling.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f282ba6a-21df-46ad-97c5-07c1f8e1b313",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Write a Python function called palindrome_prime_finder that finds all prime numbers within a given range that are also palindromes when written in base 10 (decimal system).\n",
    "\"\"\"\n",
    "\n",
    "inference_config = {\"temperature\": 0.0, \"maxTokens\": 1000, \"topP\": 0.1}\n",
    "\n",
    "response = converse(prompt, inference_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb62a27-09cf-421c-8d9e-e9a1c99a4912",
   "metadata": {},
   "source": [
    "---\n",
    "### Math and Reasoning Tasks\n",
    "\n",
    "Mistral Large 2 excels at Math and Reasoning tasks, let's test some out:\n",
    "\n",
    "1. \"Please provide a step-by-step reasoning process to estimate the number of stars in our galaxy, the Milky Way. Break down the calculation into logical steps, explaining your thought process and any assumptions you make along the way. Use scientific notation where appropriate, and conclude with a final estimate.\"\n",
    "2. \"What were the main reasons Frank Lloyd Wright designed his Oak Park Studio with high windows placed near the ceiling, and how did this feature reflect his architectural philosophy and the needs of an architecture firm's workspace?\"\n",
    "3. \"Escape velocity from a neutron star: Given: A neutron star has a mass of 2.5 solar masses and a radius of 12 km. Task: Calculate the escape velocity from the surface of this neutron star in km/s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99368e37-f52e-4632-93db-f1e831629d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Calculating the orbital period of an exoplanet: Given: An exoplanet orbits its star at a distance of 2.5 AU (Astronomical Units). The star has a mass of 1.2 solar masses. Task: Calculate the orbital period of the exoplanet in Earth years.\n",
    "\"\"\"\n",
    "\n",
    "inference_config = {\"temperature\": 0.0, \"maxTokens\": 1000, \"topP\": 0.1}\n",
    "\n",
    "response = converse(prompt, inference_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db47cb59-31de-4bc1-b2b5-4d35d14af28a",
   "metadata": {},
   "source": [
    "---\n",
    "### Distributors\n",
    "\n",
    "- Amazon Web Services\n",
    "- Mistral AI"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
