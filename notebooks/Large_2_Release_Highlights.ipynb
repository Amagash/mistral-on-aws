{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f03f6b97-8960-4ef8-9f8b-4ba430c5640c",
   "metadata": {},
   "source": [
    "# Introducing Mistral Large 2 (24.07)\n",
    "\n",
    "[Mistral Large 2](https://mistral.ai/news/mistral-large-2407/) is an advanced large language model with state-of-the-art reasoning, knowledge, and coding capabilities according to Mistral. Mistral Large 2 is designed for single-node inference with long-context applications in mind – its size of 123 billion parameters allows it to run at large throughput on a single node. A significant effort was also devoted by Mistral to enhancing the model's reasoning capabilities. One of Mistral's key focuses during training was to minimize the model's tendency to \"hallucinate,\" or generate plausible-sounding but factually incorrect or irrelevant information. This was achieved by fine-tuning the model to be more cautious and discerning in its responses, ensuring that it provides reliable and accurate outputs. Additionally, the new Mistral Large is trained to acknowledge when it cannot find solutions or does not have sufficient information to provide a confident answer. Mistral Large 2 sets a new frontier in terms of performance / cost of serving on evaluation metrics. In particular, on MMLU, the pretrained version achieves an accuracy of 84.0%, and sets a new point on the performance/cost Pareto front of open models.\n",
    "\n",
    "The model is currently generally available for use on [Amazon Bedrock](https://aws.amazon.com/bedrock/), check out the [blog](https://aws.amazon.com/blogs/machine-learning/mistral-large-2-is-now-available-in-amazon-bedrock/) post for more info.\n",
    "\n",
    "In this notebook we will be demonstrating a number of different features like multilingual capabilities (optimized for character-based languages), function calling and tool use, json output, math and reasoning, and code generation with Bedrock's [Converse API](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_Converse.html).\n",
    "\n",
    "--- \n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>IMPORTANT:</b>  Mistral Large 2 is being released under the <a href=\"https://mistral.ai/licenses/MRL-0.1.md\"> Mistral Research License</a>, that allows usage and modification for research and non-commercial usages. \n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>NOTE ON BENCHMARKS:</b> The below section goes over Benchmarks from Mistral published in their blog post for <a href=\"https://mistral.ai/news/mistral-large-2407/\"> Mistral Large 2</a>. \n",
    "</div>\n",
    "\n",
    "### Multi-lingual by design\n",
    "\n",
    "Dozens of languages supported, including English, French, German, Spanish, Italian, Chinese, Japanese, Korean, Arabic, Portuguese, Dutch and Polish among others. In particular, it excels in English, French, German, Spanish, Italian, Portuguese, Dutch, Russian, Chinese, Japanese, Korean, Arabic, and Hindi. Below are the performance results of Mistral Large 2 on the multilingual MMLU benchmark from Mistral AI's official blog post on [Mistral Large 2](https://mistral.ai/news/mistral-large-2407/)\n",
    "\n",
    "#### [Performance on Multilingual MMLU (measured on the base pretrained model) --benchmarked by Mistral AI](https://mistral.ai/images/news/mistral-large-2407/mistral-large-2407-language-diversity.png)\n",
    "\n",
    "![multilingual-mmlu](imgs/mistral-large-2407-language-diversity.webp)\n",
    "\n",
    "\n",
    "---\n",
    "### Proficient in Code and Reasoning\n",
    "\n",
    "Trained on 80+ coding languages such as Python, Java, C, C++, JavaScript, Bash, Swift, Fortran. Following their experience with Codestral 22B and Codestral Mamba, Mistral has trained Mistral Large 2 on a very large proportion of code. It vastly outperforms the previous Mistral Large. \n",
    "\n",
    "#### [Performance accuracy on code generation benchmarks (all models were benchmarked through the same evaluation pipeline) --benchmarked by Mistral AI](https://mistral.ai/images/news/mistral-large-2407/mistral-large-2407-code-generation.png)\n",
    "\n",
    "![code-gen](imgs/mistral-large-2407-code-generation.png)\n",
    "\n",
    "\n",
    "#### [Performance accuracy on MultiPL-E (all models were benchmarked through the same evaluation pipeline, except for the \"paper\" row) --benchmarked by Mistral AI](https://mistral.ai/images/news/mistral-large-2407/mistral-large-2407-multiple.png)\n",
    "\n",
    "![code-multiple](imgs/mistral-large-2407-multiple.webp)\n",
    "\n",
    "---\n",
    "### [Agent-centric](https://mistral.ai/images/news/mistral-large-2407/mistral-large-2407-tool-use.png)\n",
    "\n",
    "Best-in-class agentic capabilities with native function calling and JSON outputting. Mistral Large 2 is equipped with enhanced function calling and retrieval skills and has undergone training to proficiently execute both parallel and sequential function calls, enabling it to serve as the power engine of complex business applications.\n",
    "\n",
    "---\n",
    "## Model Card\n",
    "\n",
    "<b>Available regions: US-West-2</b>\n",
    "\n",
    "<b>Model ID: mistral.mistral-large-2407-v1:0</b>\n",
    "\n",
    "<b>Context Window : 128k</b>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e889b428-f220-4aa1-866d-43910e930bb2",
   "metadata": {},
   "source": [
    "Lets get started with trying out the model on Bedrock!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9366393c-b0c6-4ee9-9ef1-9d74da0a8b6c",
   "metadata": {},
   "source": [
    "#### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ee83c4b-a59b-4ae7-a443-d23b665e660e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from boto3 import client\n",
    "from botocore.config import Config\n",
    "import json\n",
    "import logging\n",
    "from botocore.exceptions import ClientError\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd992f67-4ffc-4b01-b235-de2fcd2ee5b3",
   "metadata": {},
   "source": [
    "#### Create Bedrock Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bed39c4f-f50c-47fc-bd6a-4597594b5e37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = Config(read_timeout=2000)\n",
    "bedrock_client = boto3.client(service_name='bedrock-runtime', region_name=\"us-west-2\", config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ef8c55-7eab-4f86-ab3a-c60cb5db34c9",
   "metadata": {},
   "source": [
    "#### Instantiate model ids of mistral models being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b987d7bb-a773-4ede-9fba-4b4b4ea230a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mistral_large_v1 = 'mistral.mistral-large-2402-v1:0'\n",
    "mistral_large_2 = 'mistral.mistral-large-2407-v1:0'\n",
    "\n",
    "model_id = mistral_large_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45307e95-7e1d-41cd-a13a-a4d81d2b5f17",
   "metadata": {},
   "source": [
    "### Generating JSON  & Tool Use\n",
    "\n",
    "Mistral 2 now offers a native JSON output mode. This feature allows developers to receive the model's responses in a structured, easy-to-read format that can be readily integrated into various applications and systems. With JSON being a widely adopted data exchange standard, this capability simplifies the process of working with the model's outputs, making it more accessible and practical for developers across different domains and use cases.\n",
    "\n",
    "To generate JSON with the Converse API you will need to define a toolSpec. Here we’ve outlined an example for a travel agent company that will take passenger information and requests and convert them to JSON.\n",
    "\n",
    "Refer to this  article for more information on Generating JSON with Converse API : [Article](https://community.aws/content/2hWA16FSt2bIzKs0Z1fgJBwu589/generating-json-with-the-amazon-bedrock-converse-api?lang=en)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a30cdcb2-7f7e-49d6-9db8-c2061534c6bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the tool configuration\n",
    "import json\n",
    "tool_list = [\n",
    "    {\n",
    "        \"toolSpec\": {\n",
    "            \"name\": \"travel_agent\",\n",
    "            \"description\": \"Converts trip details as a json structure.\",\n",
    "            \"inputSchema\": {\n",
    "                \"json\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"origin_airport\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Origin airport (IATA code)\"\n",
    "                        },\n",
    "                        \"destination_airport\": {\n",
    "                            \"type\": \"boolean\",\n",
    "                            \"description\": \"Destination airport (IATA code)\"\n",
    "                        },\n",
    "                        \"departure_date\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Departure date\",\n",
    "                        }, \n",
    "                        \"return_date\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Return date\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\n",
    "                        \"origin_airport\",\n",
    "                        \"destination_airport\",\n",
    "                        \"departure_date\",\n",
    "                        \"return_date\"\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1439f636-4660-48a4-9fda-7fc54427bd44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "content = \"\"\"\n",
    "I would like to book a flight from New York (JFK) to London (LHR) for a round-trip.\n",
    "The departure date is June 15, 2023, and the return date is June 25, 2023.\n",
    "\n",
    "For the flight preferences, I would prefer to fly with Delta or United Airlines. \n",
    "My preferred departure time range is between 8 AM and 11 AM, and my preferred arrival time range is between 9 AM and 1 PM (local time in London). \n",
    "I am open to flights with one stop, but no more than that.\n",
    "Please include non-stop flight options if available.\n",
    "\"\"\"\n",
    "\n",
    "message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        { \"text\": f\"<content>{content}</content>\" },\n",
    "        { \"text\": \"Please create a well-structured JSON object representing the flight booking request, ensuring proper nesting and organization of the data. Include sample data for better understanding. Create the JSON based on the content within the <content> tags.\" }\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9835ccf3-1217-4cef-a477-82c288906085",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"origin_airport\": \"JFK\",\n",
      "    \"destination_airport\": \"LHR\",\n",
      "    \"departure_date\": \"2023-06-15\",\n",
      "    \"return_date\": \"2023-06-25\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Bedrock client configuration\n",
    "response = bedrock_client.converse(\n",
    "    modelId=model_id,\n",
    "    messages=[message],\n",
    "    inferenceConfig={\n",
    "        \"maxTokens\": 500,\n",
    "        \"temperature\": 0.1\n",
    "    },\n",
    "    toolConfig={\n",
    "        \"tools\": tool_list\n",
    "    }\n",
    ")\n",
    "\n",
    "response_message = response['output']['message']\n",
    "response_content_blocks = response_message['content']\n",
    "content_block = next((block for block in response_content_blocks if 'toolUse' in block), None)\n",
    "tool_use_block = content_block['toolUse']\n",
    "tool_result_dict = tool_use_block['input']\n",
    "\n",
    "print(json.dumps(tool_result_dict, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f339d21e-7e0d-402f-b425-0ad849f3463b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': 'a69f994f-a9c3-48e3-875b-248464b14c1a', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Wed, 24 Jul 2024 20:09:19 GMT', 'content-type': 'application/json', 'content-length': '371', 'connection': 'keep-alive', 'x-amzn-requestid': 'a69f994f-a9c3-48e3-875b-248464b14c1a'}, 'RetryAttempts': 0}, 'output': {'message': {'role': 'assistant', 'content': [{'toolUse': {'toolUseId': 'tooluse_maGq3EXpQAy6GMQ9mi4Evg', 'name': 'travel_agent', 'input': {'origin_airport': 'JFK', 'destination_airport': 'LHR', 'departure_date': '2023-06-15', 'return_date': '2023-06-25'}}}]}}, 'stopReason': 'tool_use', 'usage': {'inputTokens': 367, 'outputTokens': 74, 'totalTokens': 441}, 'metrics': {'latencyMs': 2389}}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5284f190-03d8-482f-96a5-570c1cb60526",
   "metadata": {
    "tags": []
   },
   "source": [
    "Mistral Large 2 was able to correctly take our user query and convert the appropriate information to JSON. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9347970c-0c17-43c3-9a34-bd623e6729af",
   "metadata": {},
   "source": [
    "\n",
    "### Converse API & Tool Use\n",
    "\n",
    "Mistral Large 2 also supports the Converse API & tool use. You can use the Amazon Bedrock API to give a model access to tools that can help it generate responses for messages that you send to the model. For example, you might have a chat application that lets users find out out the most popular song played on a radio station. To answer a request for the most popular song, a model needs a tool that can query and return the song information. Here we have an example for getting the correct train schedule.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b857ec47-db95-4bd0-a63a-36127e9d02a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tool configuration\n",
    "toolConfig = {\n",
    "    \"tools\": [\n",
    "        {\n",
    "            \"toolSpec\": {\n",
    "                \"name\": \"shinkansen_schedule\",\n",
    "                \"description\": \"Fetches Shinkansen train schedule departure times for a specified station and time.\",\n",
    "                \"inputSchema\": {\n",
    "                    \"json\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"station\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The station name.\"\n",
    "                            },\n",
    "                            \"departure_time\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The departure time in HH:MM format.\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"station\", \"departure_time\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "457fda19-94d0-4d63-bba0-8a3639bce2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tool configuration\n",
    "toolConfig = {\n",
    "    \"tools\": [\n",
    "        {\n",
    "            \"toolSpec\": {\n",
    "                \"name\": \"shinkansen_schedule\",\n",
    "                \"description\": \"Fetches Shinkansen train schedule departure times for a specified station and time.\",\n",
    "                \"inputSchema\": {\n",
    "                    \"json\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"station\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The station name.\"\n",
    "                            },\n",
    "                            \"departure_time\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The departure time in HH:MM format.\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"station\", \"departure_time\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a70fa882-542c-406d-810e-72607867d966",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def shinkansen_schedule(station, departure_time):\n",
    "    schedule = {\n",
    "        \"Tokyo\": {\"09:00\": \"Hikari\", \"12:00\": \"Nozomi\", \"15:00\": \"Kodama\"},\n",
    "        \"Osaka\": {\"10:00\": \"Nozomi\", \"13:00\": \"Hikari\", \"16:00\": \"Kodama\"}\n",
    "    }\n",
    "    return schedule.get(station, {}).get(departure_time, \"No train found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5dd2372f-3330-4a39-884c-bf60f8b391b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_mistral(prompt):\n",
    "    messages = [{\"role\": \"user\", \"content\": [{\"text\": prompt}]}]\n",
    "    converse_api_params = {\n",
    "        \"modelId\": model_id,\n",
    "        \"messages\": messages,\n",
    "        \"toolConfig\": toolConfig,  \n",
    "        \"inferenceConfig\": {\"temperature\": 0.0, \"maxTokens\": 400},\n",
    "    }\n",
    "\n",
    "    response = bedrock_client.converse(**converse_api_params)\n",
    "    \n",
    "    if response['output']['message']['content'][0].get('toolUse'):\n",
    "        tool_use = response['output']['message']['content'][0]['toolUse']\n",
    "        tool_name = tool_use['name']\n",
    "        tool_inputs = tool_use['input']\n",
    "\n",
    "        if tool_name == \"shinkansen_schedule\":\n",
    "            print(\"Mistral wants to use the shinkansen_schedule tool\")\n",
    "            station = tool_inputs[\"station\"]\n",
    "            departure_time = tool_inputs[\"departure_time\"]\n",
    "            \n",
    "            try:\n",
    "                result = shinkansen_schedule(station, departure_time)\n",
    "                print(\"Train schedule result:\", result)\n",
    "            except ValueError as e:\n",
    "                print(f\"Error: {str(e)}\")\n",
    "\n",
    "    else:\n",
    "        print(\"Mistral responded with:\")\n",
    "        print(response['output']['message']['content'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "05e2c11b-b406-4889-9edb-6194a2b1bbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mistral wants to use the shinkansen_schedule tool\n",
      "Train schedule result: Hikari\n"
     ]
    }
   ],
   "source": [
    "prompt_mistral(\"What train departs Tokyo at 9:00?\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a4a156-9d5c-4988-bec2-27df931cb665",
   "metadata": {
    "tags": []
   },
   "source": [
    "Mistral Large 2 was able to correctly identify the shinkansen tool and demonstrate its use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8109a915-b96c-4db7-a865-e164a7df798a",
   "metadata": {},
   "source": [
    "### Multilingual \n",
    "\n",
    "Mistral Large 2 now supports a large number of character-based languages such as Chinese, Japanese, Korean, Arabic, and Hindi. This expanded language support allows developers to build applications and services that can cater to users from diverse linguistic backgrounds. With multilingual capabilities, developers can create localized user interfaces, provide language-specific content and resources, and ensure a seamless experience for users regardless of their native language. In particular, Mistral Large 2 is efficienct with character-based languages.\n",
    "\n",
    "Here, let's try to translate customer emails generated by the author into different languages such as Hindi, Arabic, Korean, & Japanese. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e4727948-b8a4-4028-abe6-e14035469349",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails= \"\"\"\n",
    "\"I recently bought your RGB gaming keyboard and absolutely love the customizable lighting features! Can you guide me on how to set up different profiles for each game I play?\"\n",
    "\"I'm trying to use the macro keys on the gaming keyboard I just purchased, but they don't seem to be registering my inputs. Could you help me figure out what might be going wrong?\"\n",
    "\"I'm considering buying your gaming keyboard and I'm curious about the key switch types. What options are available and what are their main differences?\"\n",
    "\"I wanted to report a small issue where my keyboard's space bar is a bit squeaky. However, your quick-start guide was super helpful and I fixed it easily by following the lubrication tips. Just thought you might want to know!\"\n",
    "\"My new gaming keyboard stopped working within a week of purchase. None of the keys respond, and the lights don't turn on. I need a solution or a replacement as soon as possible.\"\n",
    "\"I've noticed that the letters on the keys of my gaming keyboard are starting to fade after several months of use. Is this covered by the warranty?\"\n",
    "\"I had an issue where my keyboard settings would reset every time I restarted my PC. I figured out it was due to a software conflict and resolved it by updating the firmware. Just wanted to ask if there are any new updates coming soon?\"\n",
    "\"I've been having trouble with the keyboard software not saving my configurations, and it's starting to get frustrating. What can be done to ensure my settings are saved permanently?\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8412383b-079f-4b87-ad43-71becb0b0859",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#prompts\n",
    "\n",
    "#japanese prompt\n",
    "zhn_prompt=f\"\"\"\n",
    "\n",
    "emails={emails}\n",
    "\n",
    "Translate the following customer emails into Chinese. Your responses must be numbered, only in Chinese, and must adhere to only translating the emails.\n",
    "\n",
    "\"\"\".format(emails=emails)\n",
    "\n",
    "#korean prompt\n",
    "arabic_prompt=f\"\"\"\n",
    "\n",
    "emails={emails}\n",
    "\n",
    "Translate the following customer emails into Korean. Your responses must be numbered, only in Korean, and must adhere to only translating the emails.\n",
    "\n",
    "\"\"\".format(emails=emails)\n",
    "\n",
    "#hindi prompt\n",
    "hindi_prompt=f\"\"\"\n",
    "\n",
    "emails={emails}\n",
    "\n",
    "Translate the following customer emails into Hindi. Your responses must be numbered, only in Hindi, and must adhere to only translating the emails.\n",
    "\n",
    "\"\"\".format(emails=emails)\n",
    "\n",
    "#arabic prompt\n",
    "arabic_prompt=f\"\"\"\n",
    "\n",
    "emails={emails}\n",
    "\n",
    "Translate the following customer emails into Arabic. Your responses must be numbered, only in Arabic, and must adhere to only translating the emails.\n",
    "\n",
    "\"\"\".format(emails=emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfee2cf-0312-41b2-8251-dd5162cc8e65",
   "metadata": {},
   "source": [
    "#### Mistral Large 2\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b7273020-d76b-4e67-b1f3-11f09add565e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. \"मैंने हाल ही में आपका RGB गेमिंग कीबोर्ड खरीदा और कस्टमाइजेबल लाइटिंग फीचर्स को बिल्कुल पसंद करता हूँ! क्या आप मुझे बता सकते हैं कि मैं हर गेम के लिए अलग-अलग प्रोफाइल कैसे सेट कर सकता हूँ?\"\n",
      "\n",
      "2. \"मैं अभी खरीदे गए गेमिंग कीबोर्ड पर मैक्रो कीज का उपयोग करने की कोशिश कर रहा हूँ, लेकिन वे मेरे इनपुट्स को रजिस्टर नहीं कर रहे हैं। क्या आप मुझे बता सकते हैं कि क्या गलत हो सकता है?\"\n",
      "\n",
      "3. \"मैं आपका गेमिंग कीबोर्ड खरीदने के बारे में सोच रहा हूँ और मुझे की स्विच टाइप्स के बारे में जानना है। क्या उपलब्ध विकल्प हैं और उनके मुख्य अंतर क्या हैं?\"\n",
      "\n",
      "4. \"मैं यह रिपोर्ट करना चाहता था कि मेरे कीबोर्ड का स्पेस बार थोड़ा सा चरमरा रहा है। हालाँकि, आपका क्विक-स्टार्ट गाइड बहुत मददगार था और मैंने लुब्रिकेशन टिप्स का पालन करके इसे आसानी से ठीक कर दिया। बस यह जानना चाहता था कि शायद आपको पता चलना चाहिए!\"\n",
      "\n",
      "5. \"मेरा नया गेमिंग कीबोर्ड खरीद के एक सप्ताह के भीतर काम करना बंद हो गया। कोई भी की जवाब नहीं दे रहा है, और लाइट्स भी नहीं चालू हो रहे हैं। मुझे एक समाधान या एक रिप्लेसमेंट जितनी जल्दी हो सके चाहिए।\"\n",
      "\n",
      "6. \"मैंने नोट किया है कि मेरे गेमिंग कीबोर्ड के कीज पर अक्षर कुछ महीनों के उपयोग के बाद फीड होने लगे हैं। क्या यह वारंटी के तहत कवर है?\"\n",
      "\n",
      "7. \"मेरे कीबोर्ड सेटिंग्स हर बार मेरे पीसी को रीस्टार्ट करने पर रीसेट हो जाती थीं। मैंने पता लगाया कि यह एक सॉफ्टवेयर कॉन्फ्लिक्ट के कारण था और फर्मवेयर अपडेट करके इसे सुलझा दिया। बस पूछना चाहता था कि क्या कोई नए अपडेट आने वाले हैं?\"\n",
      "\n",
      "8. \"मुझे कीबोर्ड सॉफ्टवेयर मेरी कॉन्फ़िगरेशन को सेव नहीं कर रहा है, और यह परेशान करने लगा है। मेरे सेटिंग्स को स्थायी रूप से सेव करने के लिए क्या किया जा सकता है?\"\n"
     ]
    }
   ],
   "source": [
    "def converse(prompt, inference_config):\n",
    "    messages = [{\"role\": \"user\", \"content\": [{\"text\": prompt}]}]\n",
    "    response = bedrock_client.converse(\n",
    "        messages=messages,\n",
    "        modelId=model_id,\n",
    "        inferenceConfig=inference_config\n",
    "    )\n",
    "    generated_text = response['output']['message']['content'][0]['text']\n",
    "    print(generated_text)\n",
    "    return generated_text, response\n",
    "\n",
    "inference_config = {\"temperature\": 0.0, \"maxTokens\": 4000, \"topP\": 0.1}\n",
    "\n",
    "#large 2 with hindi prompt\n",
    "generated_text, response = converse(hindi_prompt, inference_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1b75cc74-5077-40e3-a907-ce74d23387fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. \"اشتريت للتو لوحة مفاتيح الألعاب الخاصة بكم التي تدعم تخصيص الإضاءة وأحببتها حقًا! هل يمكنكم إرشادي على كيفية إعداد ملفات تعريف مختلفة لكل لعبة ألعبها؟\"\n",
      "2. \"أحاول استخدام مفاتيح الماكرو على لوحة مفاتيح الألعاب التي اشتريتها للتو، لكنها لا تبدو تسجل مدخلاتي. هل يمكنكم مساعدتي في معرفة ما قد يكون خاطئًا؟\"\n",
      "3. \"أفكر في شراء لوحة مفاتيح الألعاب الخاصة بكم وأنا فضولي بشأن أنواع مفاتيح التبديل. ما هي الخيارات المتاحة وما هي الاختلافات الرئيسية بينها؟\"\n",
      "4. \"أردت أن أبلغ عن مشكلة صغيرة حيث أن مفتاح المسافة في لوحة المفاتيح يصدر صوتًا صريرًا. ومع ذلك، كان دليل البدء السريع الخاص بكم مفيدًا جدًا وقمت بإصلاحه بسهولة عن طريق اتباع نصائح التزييت. فقط أردت أن تعرفوا!\"\n",
      "5. \"توقفت لوحة مفاتيح الألعاب الجديدة الخاصة بي عن العمل خلال أسبوع من الشراء. لا تستجيب أي من المفاتيح، ولا تضيء الأضواء. أحتاج إلى حل أو استبدال في أسرع وقت ممكن.\"\n",
      "6. \"لاحظت أن الحروف على مفاتيح لوحة المفاتيح الخاصة بي بدأت تتلاشى بعد عدة أشهر من الاستخدام. هل هذا مغطى بالضمان؟\"\n",
      "7. \"كانت لدي مشكلة حيث كانت إعدادات لوحة المفاتيح تعاد تعيينها كلما أعدت تشغيل جهاز الكمبيوتر الخاص بي. اكتشفت أن السبب هو تعارض برنامجي وحللته عن طريق تحديث البرنامج الثابت. أردت فقط أن أسأل إذا كان هناك أي تحديثات جديدة قادمة؟\"\n",
      "8. \"أواجه مشكلة في أن برنامج لوحة المفاتيح لا يحفظ تكويناتي، وبدأت تزعجني. ما الذي يمكن فعله لضمان حفظ إعداداتي بشكل دائم؟\"\n"
     ]
    }
   ],
   "source": [
    "#arabic with large 2\n",
    "generated_text, response = converse(arabic_prompt, inference_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83028d47-b0f6-4fe1-a0a6-4b018dd2f6f8",
   "metadata": {},
   "source": [
    "Based on the aboe responses, we can see that Mistral Large 2 performs really well with a number of character-based languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b910897a-9431-46f9-ae80-2601fc7d7325",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b57678-4123-4239-a1a5-89bf04f3c2e0",
   "metadata": {},
   "source": [
    "### Coding Tasks\n",
    "\n",
    "Mistral Large 2 has been trained on over 80 coding languages, including popular ones like Python, Java, C, C++, JavaScript, and Bash, as well as more specialized languages such as Swift and Fortran. This comprehensive language support empowers developers to tackle a wide range of coding tasks and projects across various domains and platforms. Whether you're working on web development, mobile applications, scientific computing, or system programming, Mistral 2 can assist you with code generation, debugging, refactoring, and other coding-related tasks.\n",
    "\n",
    "<mark><b>Sample coding tasks:</b></mark>\n",
    "\n",
    "1. \"Create a Python class for a multi-threaded web scraper that can handle rate limiting, proxy rotation, and dynamic content loading. Include methods for parsing HTML with BeautifulSoup and storing results in a SQLite database.\"\n",
    "2. \"Implement a Red-Black Tree data structure in C++ with methods for insertion, deletion, and rebalancing. Include a visualization function that prints the tree structure to the console.\"\n",
    "3. \"Write a Rust function that implements the Aho-Corasick string matching algorithm for efficient multi-pattern searching. Optimize it for memory usage and include comprehensive error handling.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f282ba6a-21df-46ad-97c5-07c1f8e1b313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Below is a Python function called `palindrome_prime_finder` that finds all prime numbers within a given range that are also palindromes when written in base 10.\n",
      "\n",
      "```python\n",
      "def is_prime(n):\n",
      "    \"\"\"Check if a number is prime.\"\"\"\n",
      "    if n <= 1:\n",
      "        return False\n",
      "    if n <= 3:\n",
      "        return True\n",
      "    if n % 2 == 0 or n % 3 == 0:\n",
      "        return False\n",
      "    i = 5\n",
      "    while i * i <= n:\n",
      "        if n % i == 0 or n % (i + 2) == 0:\n",
      "            return False\n",
      "        i += 6\n",
      "    return True\n",
      "\n",
      "def is_palindrome(n):\n",
      "    \"\"\"Check if a number is a palindrome.\"\"\"\n",
      "    return str(n) == str(n)[::-1]\n",
      "\n",
      "def palindrome_prime_finder(start, end):\n",
      "    \"\"\"Find all prime numbers within a given range that are also palindromes.\"\"\"\n",
      "    palindrome_primes = []\n",
      "    for num in range(start, end + 1):\n",
      "        if is_prime(num) and is_palindrome(num):\n",
      "            palindrome_primes.append(num)\n",
      "    return palindrome_primes\n",
      "\n",
      "# Example usage:\n",
      "start_range = 1\n",
      "end_range = 1000\n",
      "result = palindrome_prime_finder(start_range, end_range)\n",
      "print(f\"Palindrome primes between {start_range} and {end_range}: {result}\")\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "1. **is_prime(n)**: This function checks if a number `n` is prime. It uses a basic primality test that eliminates even numbers and numbers divisible by 3 early, then checks divisibility up to the square root of `n`.\n",
      "\n",
      "2. **is_palindrome(n)**: This function checks if a number `n` is a palindrome by converting it to a string and comparing it to its reverse.\n",
      "\n",
      "3. **palindrome_prime_finder(start, end)**: This function iterates through all numbers in the given range `[start, end]`. For each number, it checks if it is both a prime and a palindrome. If both conditions are met, the number is added to the list of palindrome primes.\n",
      "\n",
      "### Example Usage:\n",
      "The example usage finds all palindrome primes between 1 and 1000 and prints them. You can adjust the `start_range` and `end_range` variables to find palindrome primes in any desired range.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Write a Python function called palindrome_prime_finder that finds all prime numbers within a given range that are also palindromes when written in base 10 (decimal system).\n",
    "\"\"\"\n",
    "\n",
    "inference_config = {\"temperature\": 0.0, \"maxTokens\": 1000, \"topP\": 0.1}\n",
    "\n",
    "response = converse(prompt, inference_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb62a27-09cf-421c-8d9e-e9a1c99a4912",
   "metadata": {},
   "source": [
    "---\n",
    "### Math and Reasoning Tasks\n",
    "\n",
    "Mistral Large 2 excels at Math and Reasoning tasks, let's test some out:\n",
    "\n",
    "<mark>    \n",
    "<b>Sample Questions:</b></mark>\n",
    "    \n",
    "1. \"Please provide a step-by-step reasoning process to estimate the number of stars in our galaxy, the Milky Way. Break down the calculation into logical steps, explaining your thought process and any assumptions you make along the way. Use scientific notation where appropriate, and conclude with a final estimate.\"\n",
    "2. \"What were the main reasons Frank Lloyd Wright designed his Oak Park Studio with high windows placed near the ceiling, and how did this feature reflect his architectural philosophy and the needs of an architecture firm's workspace?\"\n",
    "3. \"Escape velocity from a neutron star: Given: A neutron star has a mass of 2.5 solar masses and a radius of 12 km. Task: Calculate the escape velocity from the surface of this neutron star in km/s\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "99368e37-f52e-4632-93db-f1e831629d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To calculate the orbital period of an exoplanet, we can use Kepler's Third Law, which relates the orbital period \\( P \\) of a planet to its semi-major axis \\( a \\) and the mass of the star \\( M \\). The formula for Kepler's Third Law is:\n",
      "\n",
      "\\[ P^2 = \\frac{4\\pi^2 a^3}{G(M + m)} \\]\n",
      "\n",
      "where:\n",
      "- \\( P \\) is the orbital period,\n",
      "- \\( a \\) is the semi-major axis of the orbit,\n",
      "- \\( G \\) is the gravitational constant,\n",
      "- \\( M \\) is the mass of the star,\n",
      "- \\( m \\) is the mass of the planet (which is typically much smaller than the mass of the star and can often be neglected).\n",
      "\n",
      "For simplicity, we can use a simplified version of Kepler's Third Law that assumes the mass of the planet is negligible compared to the mass of the star:\n",
      "\n",
      "\\[ P^2 = \\frac{4\\pi^2 a^3}{GM} \\]\n",
      "\n",
      "Given:\n",
      "- \\( a = 2.5 \\) AU,\n",
      "- \\( M = 1.2 \\) solar masses.\n",
      "\n",
      "First, we need to convert the semi-major axis from AU to meters. 1 AU is approximately \\( 1.496 \\times 10^{11} \\) meters.\n",
      "\n",
      "\\[ a = 2.5 \\times 1.496 \\times 10^{11} \\text{ meters} \\]\n",
      "\n",
      "Next, we need the gravitational constant \\( G \\), which is approximately \\( 6.67430 \\times 10^{-11} \\text{ m}^3 \\text{ kg}^{-1} \\text{ s}^{-2} \\).\n",
      "\n",
      "The mass of the Sun is approximately \\( 1.989 \\times 10^{30} \\) kg. Therefore, the mass of the star is:\n",
      "\n",
      "\\[ M = 1.2 \\times 1.989 \\times 10^{30} \\text{ kg} \\]\n",
      "\n",
      "Now we can plug these values into the formula:\n",
      "\n",
      "\\[ P^2 = \\frac{4\\pi^2 (2.5 \\times 1.496 \\times 10^{11})^3}{6.67430 \\times 10^{-11} \\times (1.2 \\times 1.989 \\times 10^{30})} \\]\n",
      "\n",
      "Let's calculate \\( P \\):\n",
      "\n",
      "\\[ P^2 = \\frac{4\\pi^2 (2.5 \\times 1.496 \\times 10^{11})^3}{6.67430 \\times 10^{-11} \\times (1.2 \\times 1.989 \\times 10^{30})} \\]\n",
      "\n",
      "\\[ P^2 = \\frac{4\\pi^2 (3.74 \\times 10^{11})^3}{6.67430 \\times 10^{-11} \\times 2.3868 \\times 10^{30}} \\]\n",
      "\n",
      "\\[ P^2 = \\frac{4\\pi^2 (5.58 \\times 10^{34})}{1.587 \\times 10^{20}} \\]\n",
      "\n",
      "\\[ P^2 = \\frac{2.21 \\times 10^{36}}{1.587 \\times 10^{20}} \\]\n",
      "\n",
      "\\[ P^2 = 1.39 \\times 10^{16} \\]\n",
      "\n",
      "\\[ P = \\sqrt{1.39 \\times 10^{16}} \\]\n",
      "\n",
      "\\[ P \\approx 3.73 \\times 10^8 \\text{ seconds} \\]\n",
      "\n",
      "To convert this to Earth years, we use the fact that there are approximately \\( 3.154 \\times 10^7 \\) seconds in one Earth year:\n",
      "\n",
      "\\[ P \\approx \\frac{3.73 \\times 10^8}{3.154 \\times 10^7} \\]\n",
      "\n",
      "\\[ P \\approx 11.8 \\text{ Earth years} \\]\n",
      "\n",
      "Therefore, the orbital period of the exoplanet is approximately 11.8 Earth years.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Calculating the orbital period of an exoplanet: Given: An exoplanet orbits its star at a distance of 2.5 AU (Astronomical Units). The star has a mass of 1.2 solar masses. Task: Calculate the orbital period of the exoplanet in Earth years.\n",
    "\"\"\"\n",
    "\n",
    "inference_config = {\"temperature\": 0.0, \"maxTokens\": 1000, \"topP\": 0.1}\n",
    "\n",
    "response = converse(prompt, inference_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db47cb59-31de-4bc1-b2b5-4d35d14af28a",
   "metadata": {},
   "source": [
    "---\n",
    "### Distributors\n",
    "\n",
    "- Amazon Web Services\n",
    "- Mistral AI"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
